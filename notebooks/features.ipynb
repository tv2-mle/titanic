{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06159579-0b9f-4bf9-a4d1-7aace89e1f70",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install databricks-feature-engineering\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8be1fc47-1bc8-49f9-8cbb-50a2039493f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"train_table_raw\", \"dp_ml_titanic_train_raw\")\n",
    "dbutils.widgets.text(\"test_table_raw\", \"dp_ml_titanic_test_raw\")\n",
    "\n",
    "train_table_raw = dbutils.widgets.get(\"train_table_raw\")\n",
    "test_table_raw = dbutils.widgets.get(\"test_table_raw\")\n",
    "\n",
    "# Set catalog and schema (adjust if needed)\n",
    "spark.sql(\"USE CATALOG dp_ml_raw\")\n",
    "spark.sql(\"USE dp_ml_raw.dp_ml_titanic\")\n",
    "\n",
    "# Create the Delta table directly from the CSV files in the Volume\n",
    "spark.sql(f\"\"\"\n",
    "CREATE table IF NOT EXISTS dp_ml_raw.dp_ml_titanic.{train_table_raw}\n",
    "USING DELTA\n",
    "CLUSTER BY (PassengerId)\n",
    "SELECT *\n",
    "FROM read_files(\n",
    "  'dbfs:/Volumes/dp_ml_raw/dp_ml_titanic/titanic_raw_data/train.csv',\n",
    "  format => 'csv',\n",
    "  header => true,\n",
    "  inferSchema => true\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "CREATE table IF NOT EXISTS dp_ml_raw.dp_ml_titanic.{test_table_raw}\n",
    "USING DELTA\n",
    "CLUSTER BY (PassengerId)\n",
    "SELECT *\n",
    "FROM read_files(\n",
    "  'dbfs:/Volumes/dp_ml_raw/dp_ml_titanic/titanic_raw_data/test.csv',\n",
    "  format => 'csv',\n",
    "  header => true,\n",
    "  inferSchema => true\n",
    ")\n",
    "          \"\"\")\n",
    "\n",
    "# Preview a few rows\n",
    "display(spark.table(f\"dp_ml_raw.dp_ml_titanic.{train_table_raw}\").limit(10))\n",
    "df_train = spark.sql(f\"SELECT * FROM dp_ml_raw.dp_ml_titanic.{train_table_raw}\")\n",
    "df_test = spark.sql(f\"SELECT * FROM dp_ml_raw.dp_ml_titanic.{test_table_raw}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a964ae05-5097-490f-9c8e-a449e0ebfb3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df_train to pandas: \n",
    "df = df_train.toPandas()\n",
    "# --- Prepare X, y ---\n",
    "X = df\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# --- Config ---\n",
    "TARGET = \"Survived\"   # change if needed\n",
    "DROP_COLS = ['PassengerId', 'Name', 'Ticket', '_rescued_data', 'Cabin']\n",
    "\n",
    "# Explicit categories (order defines output column order)\n",
    "CUSTOM_CATS = {\n",
    "    \"Embarked\": [\"S\", \"C\", \"Q\"],\n",
    "    \"Sex\": [\"male\", \"female\"]\n",
    "}\n",
    "\n",
    "# --- Step 1: helper to drop cols and fillna(0) ---\n",
    "def drop_and_fill(X: pd.DataFrame) -> pd.DataFrame:\n",
    "    X = X.drop(columns=[c for c in DROP_COLS if c in X.columns])\n",
    "    return X.fillna(0)\n",
    "\n",
    "dropper = FunctionTransformer(drop_and_fill)\n",
    "\n",
    "cat_cols = [c for c in CUSTOM_CATS.keys() if c in X.columns]\n",
    "num_cols = [c for c in X.columns if c not in cat_cols and c not in DROP_COLS]\n",
    "categories_in_order = [CUSTOM_CATS[c] for c in cat_cols]\n",
    "\n",
    "print(cat_cols, num_cols, categories_in_order, TARGET)\n",
    "\n",
    "# --- OneHotEncoder with fixed categories ---\n",
    "cat_ohe = OneHotEncoder(\n",
    "    categories=categories_in_order,\n",
    "    handle_unknown=\"ignore\",   # unseen â†’ all zeros\n",
    "    sparse_output=False\n",
    ")\n",
    "\n",
    "pre = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", cat_ohe, cat_cols),\n",
    "        (\"num\", \"passthrough\", num_cols),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "# --- Full pipeline ---\n",
    "pipe = Pipeline(steps=[\n",
    "    (\"prep\", dropper),\n",
    "    (\"encode\", pre)\n",
    "])\n",
    "\n",
    "# Make sklearn respect DataFrame column names from transformers\n",
    "pipe.set_output(transform=\"pandas\")\n",
    "\n",
    "X_transformed = pipe.fit_transform(X)\n",
    "print(X_transformed.head(2))\n",
    "print(X_transformed.isnull().any().any())\n",
    "print(X_transformed.columns, df.columns)\n",
    "\n",
    "# --- 1) Log the transformer pipeline to MLflow ---\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "mlflow.set_experiment(\"/Shared/titanic-feature-pipeline\")  # pick your path\n",
    "\n",
    "with mlflow.start_run():\n",
    "    # If not already fitted, fit now (you can comment this out if pipe is fitted)\n",
    "    # pipe.fit(X, y)\n",
    "    \n",
    "    X_sig = X.head(5).copy()\n",
    "    int_like = X_sig.select_dtypes(include=[\"int64\", \"int32\", \"Int64\", \"Int32\"]).columns\n",
    "    X_sig[int_like] = X_sig[int_like].astype(\"float64\")\n",
    "\n",
    "    # Signature: raw input -> transformed output\n",
    "    sig = infer_signature(model_input=X_sig, model_output=pipe.transform(X_sig))\n",
    "\n",
    "    run_model_info = mlflow.sklearn.log_model(\n",
    "        sk_model=pipe,\n",
    "        artifact_path=\"feature_transformer\",\n",
    "        signature=sig,\n",
    "        registered_model_name=\"titanic_feature_pipeline\"  # <- choose any registry name\n",
    "    )\n",
    "\n",
    "print(\"Logged to MLflow. Model URI:\", run_model_info.model_uri)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb17f707-66d0-4813-9e1e-a29e39e44373",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.feature_engineering import FeatureEngineeringClient\n",
    "CATALOG = \"dp_ml_raw\"             # your UC catalog\n",
    "SCHEMA  = \"features\"         # your UC schema\n",
    "TABLE   = \"titanic_features\" # feature table name\n",
    "FULL    = f\"{CATALOG}.{SCHEMA}.{TABLE}\"\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {CATALOG}.{SCHEMA}\")\n",
    "\n",
    "X_features = X_transformed.reset_index().rename(columns={\"index\": \"rowId\"})\n",
    "spark_df = spark.createDataFrame(X_features)\n",
    "fe = FeatureEngineeringClient()\n",
    "\n",
    "# X_transformed should include the primary key (e.g., passenger_id)\n",
    "try:\n",
    "    fe.drop_table(name=FULL)   # removes FE metadata and underlying Delta table\n",
    "    print(f\"[info] Dropped feature table metadata: {FULL}\")\n",
    "except Exception as e:\n",
    "    print(f\"[info] fe.drop_table skipped: {e}\")\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {FULL}\")\n",
    "\n",
    "fe = FeatureEngineeringClient()\n",
    "\n",
    "# One-time create (Delta table + feature-table metadata in UC)\n",
    "# Requirements: feature tables must have a primary key\n",
    "ft = fe.create_table(\n",
    "    name=FULL,\n",
    "    primary_keys=[\"rowId\"],\n",
    "    df=spark_df,                       # writes data & schema\n",
    "    description=\"Titanic engineered features with fixed OHE\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "features",
   "widgets": {
    "catalog": {
     "currentValue": "main",
     "nuid": "1210bbbb-3792-4447-8adf-8af5b0e4b11a",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "main",
      "label": null,
      "name": "catalog",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "main",
      "label": null,
      "name": "catalog",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "test_table_raw": {
     "currentValue": "dp_ml_titanic_test_raw",
     "nuid": "e75cd5d2-4310-4289-a2fe-7960b5965039",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "dp_ml_titanic_test_raw",
      "label": null,
      "name": "test_table_raw",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "dp_ml_titanic_test_raw",
      "label": null,
      "name": "test_table_raw",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "train_table_raw": {
     "currentValue": "dp_ml_titanic_train_raw",
     "nuid": "82c24627-40a1-4756-9aa5-79d19f3b6675",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "dp_ml_titanic_train_raw",
      "label": null,
      "name": "train_table_raw",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "dp_ml_titanic_train_raw",
      "label": null,
      "name": "train_table_raw",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
